{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8DiaV5giFQ1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import pickle\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2C28x7CeIIrt",
    "outputId": "37712610-b56e-41ee-ec7e-fb5bd3b5c493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe7aca072b0>\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model.summary()\n",
    "c1 = model.layers[-16]\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKrOWBOXiUwE"
   },
   "outputs": [],
   "source": [
    "def save_all_features(nb_samples, source=\"images\", dest=\"features\", input_size = (416, 416), batch_size=6):\n",
    "    \n",
    "    # check if the directory exists, and if not make it\n",
    "    if not os.path.exists(dest):\n",
    "        os.makedirs(dest)\n",
    "    \n",
    "    # define image height and width\n",
    "    (img_height, img_width) = input_size\n",
    "    \n",
    "    # build the VGG16 network and extract features after every MaxPool layer\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    c1 = model.layers[-16].output \n",
    "    c1 = GlobalAveragePooling2D()(c1)       \n",
    "\n",
    "    c2 = model.layers[-13].output\n",
    "    c2 = GlobalAveragePooling2D()(c2)       \n",
    "\n",
    "    c3 = model.layers[-9].output\n",
    "    c3 = GlobalAveragePooling2D()(c3)       \n",
    "\n",
    "    c4 = model.layers[-5].output\n",
    "    c4 = GlobalAveragePooling2D()(c4)       \n",
    "\n",
    "    c5 = model.layers[-1].output\n",
    "    c5 = GlobalAveragePooling2D()(c5)       \n",
    "\n",
    "    model = Model(inputs=model.input, outputs=(c1,c2,c3,c4,c5))\n",
    "    \n",
    "    # define image generator without augmentation\n",
    "    datagen = ImageDataGenerator(rescale=1./255.)    \n",
    "    generator = datagen.flow_from_directory(\n",
    "            source,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"sparse\",\n",
    "            shuffle=False)\n",
    "    \n",
    "    # generate and save features, labels and respective filenames\n",
    "    steps = nb_samples/batch_size+1\n",
    "    X = model.predict_generator(generator,steps)\n",
    "    Y = np.concatenate([generator.next()[1] for i in range(0, generator.samples, batch_size)])\n",
    "    names = generator.filenames\n",
    "\n",
    "    for n, i in enumerate(X):\n",
    "        with open(dest+\"X-\"+str(img_height)+\"-c\"+str(n+1)+\"-AVG.npy\", 'wb') as f:\n",
    "                np.save(f, i)\n",
    "    if not os.path.exists(dest+\"Y.npy\"):\n",
    "        with open(dest+\"Y.npy\"  , 'wb') as f:\n",
    "            np.save(f, Y)\n",
    "    if not os.path.exists(dest+\"filenames.npy\"):\n",
    "        with open(dest+\"filenames.npy\"  , 'wb') as f:\n",
    "            np.save(f, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7quXL3Cgxolx"
   },
   "outputs": [],
   "source": [
    "def kfoldSVM_on_features(X, Y, modelname='0'):\n",
    "    # define 10-fold cross validation test harness\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=555)\n",
    "    cvscores, splits = [],[]\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        clf = LinearSVC(C=1, loss='squared_hinge', penalty='l2',multi_class='ovr', max_iter=100000)\n",
    "        clf.fit(X[train], Y[train])\n",
    "        y_pred = clf.predict(X[test])\n",
    "        acc = accuracy_score(Y[test],y_pred)*100\n",
    "        cvscores.append(acc)\n",
    "        splits.append((Y[test], y_pred))\n",
    "\n",
    "        filename = ('finalized_model_' + str(modelname) + '.sav')\n",
    "        pickle.dump(clf, open(filename, 'wb'))\n",
    "    print(\"Accuracy score averaged across 10 kfolds %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    return np.mean(cvscores), np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ1SWu8JuFaf"
   },
   "outputs": [],
   "source": [
    "def evaluate(dest=\"features\", size=416, strategy = \"-AVG\"):\n",
    "    #\n",
    "    size = str(size)\n",
    "    l1 = np.load(dest+\"X-\"+size+\"-c1\"+strategy+\".npy\")\n",
    "    l2 = np.load(dest+\"X-\"+size+\"-c2\"+strategy+\".npy\")\n",
    "    l3 = np.load(dest+\"X-\"+size+\"-c3\"+strategy+\".npy\")\n",
    "    l4 = np.load(dest+\"X-\"+size+\"-c4\"+strategy+\".npy\")\n",
    "    l5 = np.load(dest+\"X-\"+size+\"-c5\"+strategy+\".npy\")\n",
    "    a_all = np.concatenate([l1,l2,l3,l4,l5], 1)\n",
    "    \n",
    "    X =[l1, l2, l3, l4, l5, a_all]\n",
    "    \n",
    "    Y = np.load(dest +\"Y.npy\")\n",
    "    acc_no_norm = []\n",
    "    acc_norm = []\n",
    "    x = a_all\n",
    "    print(\"with square root normalization\")\n",
    "    x = np.sqrt(np.abs(x)) * np.sign(x)\n",
    "    acc_norm.append(kfoldSVM_on_features(x, Y, modelname='with'))\n",
    "    \n",
    "    return acc_no_norm, acc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7R8Hl2huQyK",
    "outputId": "c3c76378-8a52-4372-e9e3-569a3ef7059a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10277 images belonging to 25 classes.\n",
      "WARNING:tensorflow:From <ipython-input-3-80dd9539876a>:41: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 206.56 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "\n",
      "evaluating dataset with input size (416, 416) and GlobalAveragePooling2D\n",
      "with square root normalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "input_size = (416,416)\n",
    "nb_samples = 10278\n",
    "save_all_features(nb_samples, source=\"/content/datos/datos rede/train\", dest=\"/content/features/\", input_size=input_size, batch_size=50)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"evaluating dataset with input size\", input_size, \"and GlobalAveragePooling2D\")\n",
    "\n",
    "acc_no_norm, acc_norm = evaluate(dest=\"./features/\", size=input_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFBnq8GAGzmf",
    "outputId": "b337de42-b4c7-47a8-e293-cd0b70b849a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(91.2841932841933, 2.461344239154871)]\n",
      "[(93.19328419328419, 2.9440327289447317)]\n"
     ]
    }
   ],
   "source": [
    "print(acc_no_norm)\n",
    "print(acc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDhJb-E1K4MA"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = '/content/datos/datos_reducido/val/Triturus marmoratus/https3A2F2Fobservation.org2Fphotos2F1414769.jpg'\n",
    "# Open the image form working directory\n",
    "image = Image.open(image_path)\n",
    "data = np.asarray(image)\n",
    "y = np.expand_dims(data, axis=0)\n",
    "print(y.shape)\n",
    "imgplot = plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AD2H6cN9OURj"
   },
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "c1 = model.layers[-16].output \n",
    "c1 = GlobalAveragePooling2D()(c1)       \n",
    "c2 = model.layers[-13].output\n",
    "c2 = GlobalAveragePooling2D()(c2)       \n",
    "c3 = model.layers[-9].output\n",
    "c3 = GlobalAveragePooling2D()(c3)       \n",
    "c4 = model.layers[-5].output\n",
    "c4 = GlobalAveragePooling2D()(c4)       \n",
    "c5 = model.layers[-1].output\n",
    "c5 = GlobalAveragePooling2D()(c5)  \n",
    "model = Model(inputs=model.input, outputs=(c1,c2,c3,c4,c5))\n",
    "X = model.predict(y)\n",
    "\n",
    "a_all = np.concatenate([X[0],X[1],X[2],X[3],X[4]], 1)\n",
    "\n",
    "\n",
    "\n",
    "filename = '/content/finalized_model_5without.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(a_all)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiyc70SpXc6p"
   },
   "outputs": [],
   "source": [
    "a = np.load(\"/content/features/Y.npy\")\n",
    "b = np.load(\"/content/features/X-400-c1-AVG.npy\")\n",
    "c = np.load(\"/content/features/X-400-c2-AVG.npy\")\n",
    "files = np.load(\"/content/features/filenames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDP7vZX_X0BO"
   },
   "outputs": [],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(files.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copia de Automated Taxonomic Identification (transfer features).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
